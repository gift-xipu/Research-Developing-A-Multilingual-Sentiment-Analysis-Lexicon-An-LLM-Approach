{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a103055-d8df-4852-9ff7-d8ad00940413",
   "metadata": {},
   "source": [
    "# Multilingual Sentiment Analysis Lexicons for African Languages: An LLM Approach\n",
    "\n",
    "This notebook implements the methodology and findings from research conducted by Gift Markus Xipu on **\"Multilingual Sentiment Analysis Lexicons for African Languages: An LLM Approach.\"** \n",
    "\n",
    "Our study evaluates the capabilities of large language models (OpenAI, Claude, Gemini, and BERT) to perform sentiment analysis directly on African languages, specifically Sepedi, Sesotho, and Setswana, without relying on translation-based techniques. We examine the effectiveness of various prompting strategies and assess the degree of fine-tuning required to optimise performance across these languages.\n",
    "\n",
    "The code provided here demonstrates how to leverage these LLMs to create sentiment lexicons and analyse African language text, representing a step toward more culturally and linguistically inclusive NLP tools. The approach aims to address the critical gap in NLP resources for African languages by utilising the multilingual capabilities of modern language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd62a7-5f3d-4b08-87c4-c7204df1e09d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    Importing the necessary dependencies\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f575117-eea6-4578-af8c-7a638455b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import  google.generativeai as genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee54c4-83ac-42dc-9667-fa934f8cd573",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong> This defines the base <code>LLM</code> class that serves as an abstract interface for all language models. It stores common attributes (name, API key, model identifier, temperature, and token limits) and declares abstract methods that child classes must implement. The <code>setup_client()</code> method will establish connections to model APIs, while <code>generate()</code> will handle prompt submission and response retrieval. Each language model implementation (Claude, OpenAI, Gemini) will extend this class with their specific functionality.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15a7865-7f93-4dd1-94c3-31f27b3de721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, name, api_key, model, temperature=0.0, max_tokens=1000):\n",
    "\n",
    "        self.name = name\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.client = None\n",
    "    \n",
    "    def setup_client(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement setup_client()\")\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        raise NotImplementedError(\"Subclasses must implement generate()\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.name}(model='{self.model}')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10097fd8-d095-47f5-bfac-92807265874a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1ecff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Claude Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c17979-825a-44e0-8b31-cc362b84585f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong> This code implements the Claude-specific LLM subclass. The <code>ClaudeLLM</code> class inherits from the base <code>LLM</code> class and provides Claude-specific implementations for client setup and text generation. It initializes with default values optimized for Claude (using the latest claude-3-7-sonnet model and 4096 token limit). The <code>generate()</code> method formats the request according to Claude's API requirements, handling both standard prompts and optional system prompts. The code then initializes a Claude instance with the provided API key, sets the temperature to 0 for deterministic responses, and establishes the connection to Anthropic's API.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90a9c708-ac84-45a8-aa8c-dd1b7c8483e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude setup complete: Claude(model='claude-3-7-sonnet-20250219')\n"
     ]
    }
   ],
   "source": [
    "# Claude-specific implementation\n",
    "class ClaudeLLM(LLM):\n",
    "    def __init__(self, api_key, model=\"claude-3-7-sonnet-20250219\", temperature=0.0, max_tokens=4096):\n",
    "        super().__init__(\"Claude\", api_key, model, temperature, max_tokens)\n",
    "    \n",
    "    def setup_client(self):\n",
    "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
    "        return self.client\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        # Set up client if not already done\n",
    "        if not self.client:\n",
    "            self.setup_client()\n",
    "        \n",
    "        # Prepare the message parameters\n",
    "        message_params = {\n",
    "            \"model\": self.model,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Add system prompt if provided\n",
    "        if system_prompt:\n",
    "            message_params[\"system\"] = system_prompt\n",
    "        \n",
    "        # Send request to Claude\n",
    "        response = self.client.messages.create(**message_params)\n",
    "        \n",
    "        # Return the text response\n",
    "        return response.content[0].text\n",
    "\n",
    "\n",
    "# Now initialize a Claude instance (replace with your API key)\n",
    "CLAUDE_API_KEY = \"Add key\"\n",
    "\n",
    "# Create the Claude instance\n",
    "claude = ClaudeLLM(\n",
    "    api_key=CLAUDE_API_KEY,\n",
    "    temperature=0.0  # Deterministic responses as requested\n",
    ")\n",
    "\n",
    "# Setup the client\n",
    "claude.setup_client()\n",
    "\n",
    "# Verify setup\n",
    "print(f\"Claude setup complete: {claude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568be56e-1fe2-43f2-aa6f-7c8c0903b979",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c8e6c9; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>OpenAI Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4adc0385-8ae1-4dea-a95b-bae9525d8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI setup complete: OpenAI(model='gpt-4o')\n"
     ]
    }
   ],
   "source": [
    "# OpenAI-specific implementation\n",
    "class OpenAILLM(LLM):\n",
    "    def __init__(self, api_key, model=\"gpt-4o\", temperature=0.0, max_tokens=4096):\n",
    "        \"\"\"\n",
    "        Initialize an OpenAI LLM instance.\n",
    "        \n",
    "        Args:\n",
    "            api_key (str): The OpenAI API key for authentication\n",
    "            model (str): The OpenAI model to use (default: gpt-4o)\n",
    "            temperature (float): Controls randomness (0.0 to 1.0)\n",
    "            max_tokens (int): Maximum tokens in the response\n",
    "        \"\"\"\n",
    "        # Call the parent constructor with the name \"OpenAI\"\n",
    "        super().__init__(\"OpenAI\", api_key, model, temperature, max_tokens)\n",
    "        self.base_url = None  # Optional base URL for API requests\n",
    "    \n",
    "    def setup_client(self):\n",
    "        \"\"\"Set up the OpenAI client.\"\"\"\n",
    "        if self.base_url:\n",
    "            self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "        else:\n",
    "            self.client = OpenAI(api_key=self.api_key)\n",
    "        return self.client\n",
    "    \n",
    "    def set_base_url(self, base_url):\n",
    "        \"\"\"\n",
    "        Set a custom base URL for API requests (useful for proxies or Azure OpenAI).\n",
    "        \n",
    "        Args:\n",
    "            base_url (str): The base URL to use for API requests\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        # Reset client if it was already set up\n",
    "        if self.client:\n",
    "            self.setup_client()\n",
    "        return self\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        \"\"\"\n",
    "        Generate a response from OpenAI.\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): The user prompt\n",
    "            system_prompt (str, optional): System instructions for the AI\n",
    "            \n",
    "        Returns:\n",
    "            str: OpenAI's response\n",
    "        \"\"\"\n",
    "        # Set up client if not already done\n",
    "        if not self.client:\n",
    "            self.setup_client()\n",
    "        \n",
    "        # Prepare the messages list\n",
    "        messages = []\n",
    "        \n",
    "        # Add system prompt if provided\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        # Add user prompt\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # Send request to OpenAI\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        # Return the text response\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Now initialize an OpenAI instance (replace with your API key)\n",
    "OPENAI_API_KEY= \"add key\"\n",
    "\n",
    "# Create the OpenAI instance\n",
    "openai_llm = OpenAILLM(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.0  # Deterministic responses as requested\n",
    ")\n",
    "\n",
    "# Setup the client\n",
    "openai_llm.setup_client()\n",
    "\n",
    "# Verify setup\n",
    "print(f\"OpenAI setup complete: {openai_llm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a822806c-1b27-43b1-8172-a5ba10105b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualSentimentBearings:\n",
    "    \n",
    "    # Language codes and names\n",
    "    LANGUAGES = {\n",
    "        'sepedi': 'Sepedi',\n",
    "        'sesotho': 'Sesotho',\n",
    "        'setswana': 'Setswana'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, llm_model):\n",
    "        \"\"\"\n",
    "        Initialize with an LLM model instance.\n",
    "        \n",
    "        Args:\n",
    "            llm_model: An instance of an LLM class (Claude, OpenAI, etc.)\n",
    "        \"\"\"\n",
    "        self.llm = llm_model\n",
    "        \n",
    "    def get_bearing_prompt(self, word, language):\n",
    "        \"\"\"\n",
    "        Generate a prompt to determine the sentiment bearing of a word in the specified language.\n",
    "        \n",
    "        Args:\n",
    "            word (str): The word to analyze\n",
    "            language (str): The language code ('sepedi', 'sesotho', or 'setswana')\n",
    "            \n",
    "        Returns:\n",
    "            str: A prompt for the LLM\n",
    "        \"\"\"\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        return f\"\"\"\n",
    "        Analyze the sentiment bearing of the {language_name} word: \"{word}\"\n",
    "        \n",
    "        Please respond with ONLY a single line in exactly this format:\n",
    "        <word>, <sentiment>, <score>\n",
    "        \n",
    "        Where:\n",
    "        - <word> is the analyzed word in {language_name}\n",
    "        - <sentiment> is either \"positive\", \"neutral\", or \"negative\" in English\n",
    "        - <score> is either 1 (positive), 0 (neutral), or -1 (negative)\n",
    "        \n",
    "        For example:\n",
    "        lerato, positive, 1\n",
    "        thata, neutral, 0\n",
    "        bohloko, negative, -1\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_bearing_system_prompt(self, language):\n",
    "        \"\"\"\n",
    "        Generate a system prompt for sentiment bearing analysis in the specified language.\n",
    "        \n",
    "        Args:\n",
    "            language (str): The language code ('sepedi', 'sesotho', or 'setswana')\n",
    "            \n",
    "        Returns:\n",
    "            str: A system prompt with instructions\n",
    "        \"\"\"\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        return f\"\"\"\n",
    "        You are a precise sentiment analyzer for the {language_name} language. Your task is to determine \n",
    "        if a {language_name} word has a positive, neutral, or negative sentiment bearing.\n",
    "        \n",
    "        Respond with ONLY a single line containing the word, sentiment (in English), and score (-1, 0, or 1) \n",
    "        in the exact format requested. Do not include any explanations or additional text.\n",
    "        \n",
    "        Be objective in your analysis and ensure you understand the cultural context and nuances of \n",
    "        the {language_name} language.\n",
    "        \"\"\"\n",
    "    \n",
    "    def analyze_word(self, word, language):\n",
    "        \"\"\"\n",
    "        Analyze the sentiment bearing of a single word in the specified language.\n",
    "        \n",
    "        Args:\n",
    "            word (str): The word to analyze\n",
    "            language (str): The language code ('sepedi', 'sesotho', or 'setswana')\n",
    "            \n",
    "        Returns:\n",
    "            dict: A dictionary with the word, language, sentiment, and score\n",
    "        \"\"\"\n",
    "        if language.lower() not in self.LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language: {language}. Supported languages are: {', '.join(self.LANGUAGES.keys())}\")\n",
    "        \n",
    "        prompt = self.get_bearing_prompt(word, language)\n",
    "        system_prompt = self.get_bearing_system_prompt(language)\n",
    "        \n",
    "        # Get response from the LLM\n",
    "        response = self.llm.generate(prompt, system_prompt=system_prompt)\n",
    "        \n",
    "        # Parse the response (expecting format: \"word, sentiment, score\")\n",
    "        try:\n",
    "            # Clean the response and split by comma\n",
    "            clean_response = response.strip()\n",
    "            parts = clean_response.split(',')\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                analyzed_word = parts[0].strip()\n",
    "                sentiment = parts[1].strip().lower()\n",
    "                score_str = parts[2].strip()\n",
    "                \n",
    "                # Convert score to int\n",
    "                try:\n",
    "                    score = int(score_str)\n",
    "                except ValueError:\n",
    "                    # If score is not an integer, try to extract it from the string\n",
    "                    if '-1' in score_str:\n",
    "                        score = -1\n",
    "                    elif '1' in score_str and not score_str.startswith('-'):\n",
    "                        score = 1\n",
    "                    else:\n",
    "                        score = 0\n",
    "                \n",
    "                return {\n",
    "                    'word': analyzed_word,\n",
    "                    'language': language.lower(),\n",
    "                    'sentiment': sentiment,\n",
    "                    'score': score\n",
    "                }\n",
    "            else:\n",
    "                # If parsing fails, return a default response\n",
    "                print(f\"Warning: Could not parse LLM response correctly. Raw response: {response}\")\n",
    "                return {\n",
    "                    'word': word,\n",
    "                    'language': language.lower(),\n",
    "                    'sentiment': 'unknown',\n",
    "                    'score': None,\n",
    "                    'raw_response': response\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing LLM response: {e}\")\n",
    "            return {\n",
    "                'word': word,\n",
    "                'language': language.lower(),\n",
    "                'sentiment': 'error',\n",
    "                'score': None,\n",
    "                'error': str(e),\n",
    "                'raw_response': response\n",
    "            }\n",
    "    \n",
    "    def analyze_words(self, words_dict):\n",
    "        \"\"\"\n",
    "        Analyze the sentiment bearing of multiple words in different languages.\n",
    "        \n",
    "        Args:\n",
    "            words_dict (dict): A dictionary where keys are language codes and values are\n",
    "                              lists of words to analyze in that language\n",
    "            \n",
    "        Returns:\n",
    "            dict: A dictionary with language codes as keys and lists of analysis results as values\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for language, words in words_dict.items():\n",
    "            language_results = []\n",
    "            \n",
    "            for word in words:\n",
    "                result = self.analyze_word(word, language)\n",
    "                language_results.append(result)\n",
    "                \n",
    "            results[language] = language_results\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def create_sentiment_lexicon(self, words_dict):\n",
    "        \"\"\"\n",
    "        Create a sentiment lexicon for multiple languages.\n",
    "        \n",
    "        Args:\n",
    "            words_dict (dict): A dictionary where keys are language codes and values are\n",
    "                              lists of words to analyze in that language\n",
    "            \n",
    "        Returns:\n",
    "            dict: A multilingual sentiment lexicon\n",
    "        \"\"\"\n",
    "        lexicon = {}\n",
    "        \n",
    "        for language, words in words_dict.items():\n",
    "            language_lexicon = {}\n",
    "            \n",
    "            for word in words:\n",
    "                result = self.analyze_word(word, language)\n",
    "                if result['score'] is not None:\n",
    "                    language_lexicon[word] = result['score']\n",
    "                \n",
    "            lexicon[language] = language_lexicon\n",
    "            \n",
    "        return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99149484-cc4a-4756-abbc-64c7cff4f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilingual analyzer initialized successfully\n",
      "Starting multilingual sentiment analysis...\n",
      "\n",
      "Sentiment Analysis Results for Sepedi:\n",
      "Word            | Sentiment  | Score\n",
      "-----------------------------------\n",
      "manyami         | negative   | -1   \n",
      "thabo           | positive   | 1    \n",
      "kgahlego        | positive   | 1    \n",
      "\n",
      "Sentiment Analysis Results for Sesotho:\n",
      "Word            | Sentiment  | Score\n",
      "-----------------------------------\n",
      "lerato          | positive   | 1    \n",
      "thabo           | positive   | 1    \n",
      "thahasello      | positive   | 1    \n",
      "\n",
      "Sentiment Analysis Results for Setswana:\n",
      "Word            | Sentiment  | Score\n",
      "-----------------------------------\n",
      "botlhoko        | negative   | -1   \n",
      "boitumelo       | positive   | 1    \n",
      "kgatlhego       | positive   | 1    \n",
      "\n",
      "Multilingual sentiment analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Test the multilingual sentiment analysis\n",
    "\n",
    "# Make sure your LLM is initialized with the correct API key\n",
    "# For example:\n",
    "# claude = ClaudeLLM(api_key=\"your_actual_api_key_here\")\n",
    "# claude.setup_client()\n",
    "\n",
    "# Create a MultilingualSentimentBearings instance\n",
    "try:\n",
    "    sentiment_llm = claude  # Use your initialized LLM\n",
    "    multilingual_analyzer = MultilingualSentimentBearings(sentiment_llm)\n",
    "    print(\"Multilingual analyzer initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing multilingual analyzer: {e}\")\n",
    "\n",
    "# Sample words in each language\n",
    "test_words = {\n",
    "    'sepedi': [\n",
    "        'manyami',     # love\n",
    "        'thabo',      # joy\n",
    "        'kgahlego',   # interest\n",
    "        'pefelo',     # anger\n",
    "        'manyami',    # sadness\n",
    "        'poifo',      # fear\n",
    "        'botho',      # humanity/ubuntu\n",
    "        'tshele'      # life\n",
    "    ],\n",
    "    'sesotho': [\n",
    "        'lerato',     # love\n",
    "        'thabo',      # joy\n",
    "        'thahasello', # interest\n",
    "        'kgalefo',    # anger\n",
    "        'maswabi',    # sadness\n",
    "        'tshabo',     # fear\n",
    "        'botho',      # humanity/ubuntu\n",
    "        'bophelo'     # life\n",
    "    ],\n",
    "    'setswana': [\n",
    "        'botlhoko',     # love\n",
    "        'boitumelo',  # joy\n",
    "        'kgatlhego',  # interest\n",
    "        'tenego',     # anger\n",
    "        'kutlobotlhoko', # sadness\n",
    "        'poifo',      # fear\n",
    "        'botho',      # humanity/ubuntu\n",
    "        'botshelo'    # life\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to display sentiment analysis results for a language\n",
    "def display_language_results(language, results):\n",
    "    \"\"\"\n",
    "    Display sentiment analysis results for a specific language.\n",
    "    \n",
    "    Args:\n",
    "        language (str): The language name\n",
    "        results (list): List of result dictionaries\n",
    "    \"\"\"\n",
    "    print(f\"\\nSentiment Analysis Results for {language.title()}:\")\n",
    "    print(f\"{'Word':<15} | {'Sentiment':<10} | {'Score':<5}\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    for result in results:\n",
    "        word = result.get('word', 'unknown')\n",
    "        sentiment = result.get('sentiment', 'unknown')\n",
    "        score = result.get('score', 'N/A')\n",
    "        \n",
    "        print(f\"{word:<15} | {sentiment:<10} | {score:<5}\")\n",
    "\n",
    "# Test with a smaller subset for initial testing\n",
    "test_subset = {\n",
    "    'sepedi': test_words['sepedi'][:3],   # Just first 3 words\n",
    "    'sesotho': test_words['sesotho'][:3], # Just first 3 words\n",
    "    'setswana': test_words['setswana'][:3] # Just first 3 words\n",
    "}\n",
    "\n",
    "# Analyze words in each language\n",
    "try:\n",
    "    print(\"Starting multilingual sentiment analysis...\")\n",
    "    \n",
    "    # Use smaller subset for initial testing\n",
    "    results = multilingual_analyzer.analyze_words(test_subset)\n",
    "    \n",
    "    # Display results for each language\n",
    "    for language, language_results in results.items():\n",
    "        display_language_results(language, language_results)\n",
    "    \n",
    "    print(\"\\nMultilingual sentiment analysis completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in multilingual sentiment analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e97782c-d47c-42f1-9ccb-78aea8ed7373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
