{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a103055-d8df-4852-9ff7-d8ad00940413",
   "metadata": {},
   "source": [
    "# Multilingual Sentiment Analysis Lexicons for African Languages: An LLM Approach\n",
    "\n",
    "This notebook implements the methodology and findings from research conducted by Gift Markus Xipu on **\"Multilingual Sentiment Analysis Lexicons for African Languages: An LLM Approach.\"** \n",
    "\n",
    "Our study evaluates the capabilities of large language models (OpenAI, Claude, Gemini, and BERT) to perform sentiment analysis directly on African languages, specifically Sepedi, Sesotho, and Setswana, without relying on translation-based techniques. We examine the effectiveness of various prompting strategies and assess the degree of fine-tuning required to optimise performance across these languages.\n",
    "\n",
    "The code provided here demonstrates how to leverage these LLMs to create sentiment lexicons and analyse African language text, representing a step toward more culturally and linguistically inclusive NLP tools. The approach aims to address the critical gap in NLP resources for African languages by utilising the multilingual capabilities of modern language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd62a7-5f3d-4b08-87c4-c7204df1e09d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    Importing the necessary dependencies\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f575117-eea6-4578-af8c-7a638455b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests\n",
    "from typing import Dict, List, Tuple, Union, Optional, Any\n",
    "\n",
    "# LLM-specific imports\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee54c4-83ac-42dc-9667-fa934f8cd573",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong> This defines the base <code>LLM</code> class that serves as an abstract interface for all language models. It stores common attributes (name, API key, model identifier, temperature, and token limits) and declares abstract methods that child classes must implement. The <code>setup_client()</code> method will establish connections to model APIs, while <code>generate()</code> will handle prompt submission and response retrieval. Each language model implementation (Claude, OpenAI, Gemini) will extend this class with their specific functionality.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15a7865-7f93-4dd1-94c3-31f27b3de721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    \n",
    "    def __init__(self, name, api_key, model, temperature=0.0, max_tokens=1000):\n",
    "        self.name = name\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.client = None\n",
    "    \n",
    "    def setup_client(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement setup_client()\")\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        raise NotImplementedError(\"Subclasses must implement generate()\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.name}(model='{self.model}')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db93bf-843e-4d4a-b007-0c87edc507bc",
   "metadata": {},
   "source": [
    "## Initializing the different llms we plan to use for this project\n",
    "\n",
    "For this project we plan to use Claude, Ollama (orca-mini), Gemini and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0b781-6a83-41a0-948a-71448d28b4d9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1ecff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Claude Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f440f21-968f-498c-89de-5ccf596a50b2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong> This code implements the Claude-specific LLM subclass. The <code>ClaudeLLM</code> class inherits from the base <code>LLM</code> class and provides Claude-specific implementations for client setup and text generation. It initializes with default values optimized for Claude (using the latest claude-3-7-sonnet model and 4096 token limit). The <code>generate()</code> method formats the request according to Claude's API requirements, handling both standard prompts and optional system prompts. The code then initializes a Claude instance with the provided API key, sets the temperature to 0 for deterministic responses, and establishes the connection to Anthropic's API.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a9c708-ac84-45a8-aa8c-dd1b7c8483e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude setup complete: Claude(model='claude-3-7-sonnet-20250219')\n"
     ]
    }
   ],
   "source": [
    "# Claude-specific implementation\n",
    "class ClaudeLLM(LLM):\n",
    "    def __init__(self, api_key, model=\"claude-3-7-sonnet-20250219\", temperature=0.0, max_tokens=4096):\n",
    "        super().__init__(\"Claude\", api_key, model, temperature, max_tokens)\n",
    "    \n",
    "    def setup_client(self):\n",
    "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
    "        return self.client\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        # Set up client if not already done\n",
    "        if not self.client:\n",
    "            self.setup_client()\n",
    "        \n",
    "        # Prepare the message parameters\n",
    "        message_params = {\n",
    "            \"model\": self.model,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Add system prompt if provided\n",
    "        if system_prompt:\n",
    "            message_params[\"system\"] = system_prompt\n",
    "        \n",
    "        # Send request to Claude\n",
    "        response = self.client.messages.create(**message_params)\n",
    "        \n",
    "        # Return the text response\n",
    "        return response.content[0].text\n",
    "\n",
    "\n",
    "# Now initialize a Claude instance (replace with your API key)\n",
    "CLAUDE_API_KEY = \"\"\n",
    "\n",
    "# Create the Claude instance\n",
    "claude = ClaudeLLM(\n",
    "    api_key=CLAUDE_API_KEY,\n",
    "    temperature=0.0  # Deterministic responses as requested\n",
    ")\n",
    "\n",
    "# Setup the client\n",
    "claude.setup_client()\n",
    "\n",
    "# Verify setup\n",
    "print(f\"Claude setup complete: {claude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba71b2-09fa-4797-b2b2-b6e6d4d93daa",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #b5e64c; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>OpenAI Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c3cc8-3330-4e82-b987-e57eca055d69",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong> This OpenAILLM class creates a wrapper around OpenAI's API for text generation. It initializes with an API key and optional parameters like model type (defaulting to gpt-4o), temperature (controlling randomness), and token limit. The class provides methods to set up the client connection, configure a custom API endpoint, and generate responses by sending prompts to OpenAI's service. After defining the class, the code creates an instance with a specific API key and zero temperature for deterministic outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adc0385-8ae1-4dea-a95b-bae9525d8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI setup complete: OpenAI(model='gpt-4o')\n"
     ]
    }
   ],
   "source": [
    "# OpenAI-specific implementation\n",
    "class OpenAILLM(LLM):\n",
    "    def __init__(self, api_key, model=\"gpt-4o\", temperature=0.0, max_tokens=4096):\n",
    "        # Call the parent constructor with the name \"OpenAI\"\n",
    "        super().__init__(\"OpenAI\", api_key, model, temperature, max_tokens)\n",
    "        self.base_url = None  # Optional base URL for API requests\n",
    "    \n",
    "    def setup_client(self):\n",
    "        \"\"\"Set up the OpenAI client.\"\"\"\n",
    "        if self.base_url:\n",
    "            self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "        else:\n",
    "            self.client = OpenAI(api_key=self.api_key)\n",
    "        return self.client\n",
    "    \n",
    "    def set_base_url(self, base_url):\n",
    "        \"\"\"\n",
    "        Set a custom base URL for API requests (useful for proxies or Azure OpenAI).\n",
    "        \n",
    "        Args:\n",
    "            base_url (str): The base URL to use for API requests\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        # Reset client if it was already set up\n",
    "        if self.client:\n",
    "            self.setup_client()\n",
    "        return self\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        \"\"\"\n",
    "        Generate a response from OpenAI.\n",
    "        \n",
    "        Args:\n",
    "            prompt (str): The user prompt\n",
    "            system_prompt (str, optional): System instructions for the AI\n",
    "            \n",
    "        Returns:\n",
    "            str: OpenAI's response\n",
    "        \"\"\"\n",
    "        # Set up client if not already done\n",
    "        if not self.client:\n",
    "            self.setup_client()\n",
    "        \n",
    "        # Prepare the messages list\n",
    "        messages = []\n",
    "        \n",
    "        # Add system prompt if provided\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        # Add user prompt\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # Send request to OpenAI\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            max_tokens=self.max_tokens,\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        # Return the text response\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Now initialize an OpenAI instance (replace with your API key)\n",
    "OPENAI_API_KEY= \"\"\n",
    "\n",
    "# Create the OpenAI instance\n",
    "openai_llm = OpenAILLM(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0.0  # Deterministic responses as requested\n",
    ")\n",
    "\n",
    "# Setup the client\n",
    "openai_llm.setup_client()\n",
    "\n",
    "# Verify setup\n",
    "print(f\"OpenAI setup complete: {openai_llm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb7d83-327b-4fe7-b067-7b9282e76f00",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e393ed; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Gemini Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9037906-6a36-4794-bd9d-f522e2d0c9f3",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong>This GeminiLLM class creates a wrapper for Google's Generative AI API. It inherits from a base LLM class and initializes with an API key and optional parameters for model selection (default is gemini-1.5-pro), temperature control, and token limits. The setup_client method configures the connection to Google's API, while the generate method handles text generation by creating a configured model instance, preparing prompts (combining system and user prompts since Gemini handles them differently than OpenAI), and returning the generated text response. The code finishes by instantiating the class with an API key and zero temperature setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d571d7c-e57b-4266-bef6-f2d671c014c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini setup complete: Gemini(model='gemini-1.5-pro')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GeminiLLM(LLM):\n",
    "    def __init__(self, api_key, model=\"gemini-1.5-pro\", temperature=0.0, max_tokens=4096):\n",
    "        super().__init__(\"Gemini\", api_key, model, temperature, max_tokens)\n",
    "    \n",
    "    def setup_client(self):\n",
    "        \"\"\"Set up the Google Generative AI client.\"\"\"\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        self.client = genai\n",
    "        return self.client\n",
    "    \n",
    "    def generate(self, prompt, system_prompt=None):\n",
    "        # Set up client if not already done\n",
    "        if not self.client:\n",
    "            self.setup_client()\n",
    "        \n",
    "        # Create a generation config\n",
    "        generation_config = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_output_tokens\": self.max_tokens,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 0\n",
    "        }\n",
    "        \n",
    "        # Create the model\n",
    "        model = self.client.GenerativeModel(model_name=self.model,\n",
    "                                           generation_config=generation_config)\n",
    "        \n",
    "        # Prepare content for prompt\n",
    "        if system_prompt:\n",
    "            # For Gemini, we combine system and user prompts\n",
    "            full_prompt = f\"{system_prompt}\\n\\n{prompt}\"\n",
    "        else:\n",
    "            full_prompt = prompt\n",
    "        \n",
    "        # Generate content\n",
    "        response = model.generate_content(full_prompt)\n",
    "        \n",
    "        # Return the text response\n",
    "        return response.text\n",
    "\n",
    "        \n",
    "# Now initialize a Gemini instance (replace with your API key)\n",
    "GEMINI_API_KEY = \"\"\n",
    "\n",
    "# Create the Gemini instance\n",
    "gemini_llm = GeminiLLM(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.0  # Deterministic responses as requested\n",
    ")\n",
    "\n",
    "# Setup the client\n",
    "gemini_llm.setup_client()\n",
    "\n",
    "# Verify setup\n",
    "print(f\"Gemini setup complete: {gemini_llm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646efc4-8369-4e65-ab73-9e2d9a622e22",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f593a5; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Ollama Initialization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b1422-8a00-4994-8c8f-763975693824",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong>This OllamaLLM class creates a wrapper for running local language models through Ollama. Unlike cloud-based LLMs, it doesn't require an API key but instead connects to a local Ollama server (default: http://localhost:11434). The class initializes with model selection (default: orca-mini), temperature settings, and token limits. Its generate method handles compatibility with different Ollama client versions by trying multiple API formats and gracefully handling errors. The setup process includes error handling to alert users if the local Ollama server isn't running when the client attempts to connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff28717c-8da1-4dfd-802b-781c0a1d6c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama setup complete: Ollama(model='orca-mini')\n"
     ]
    }
   ],
   "source": [
    "class OllamaLLM(LLM):\n",
    "   \n",
    "   def __init__(self, model=\"orca-mini\", temperature=0.0, max_tokens=4096, host=\"http://localhost:11434\"):\n",
    "       # Ollama doesn't use an API key in the traditional sense\n",
    "       super().__init__(\"Ollama\", None, model, temperature, max_tokens)\n",
    "       self.host = host\n",
    "   \n",
    "   def setup_client(self):\n",
    "       self.client = ollama\n",
    "       return self.client\n",
    "       \n",
    "   def generate(self, prompt, system_prompt=None):\n",
    "       # Set up client if not already done\n",
    "       if not self.client:\n",
    "           self.setup_client()\n",
    "       \n",
    "       # Check the client's API - newer versions may use different parameters\n",
    "       # Option 1: For newer Ollama client versions\n",
    "       try:\n",
    "           options = {\n",
    "               \"temperature\": self.temperature,\n",
    "               \"num_predict\": self.max_tokens,\n",
    "           }\n",
    "           \n",
    "           if system_prompt:\n",
    "               options[\"system\"] = system_prompt\n",
    "               \n",
    "           response = self.client.generate(\n",
    "               model=self.model,\n",
    "               prompt=prompt,\n",
    "               options=options\n",
    "           )\n",
    "           \n",
    "           return response['response']\n",
    "       except TypeError:\n",
    "           # Option 2: Try alternative API format for older versions\n",
    "           try:\n",
    "               response = self.client.generate(\n",
    "                   model=self.model,\n",
    "                   prompt=prompt,\n",
    "                   system=system_prompt if system_prompt else \"\",\n",
    "               )\n",
    "               return response['response']\n",
    "           except Exception as e:\n",
    "               print(f\"Failed to generate with Ollama: {e}\")\n",
    "               return f\"Error generating response: {e}\"\n",
    "\n",
    "# Initialize Ollama (no API key needed)\n",
    "try:\n",
    "   ollama_llm = OllamaLLM(\n",
    "       model=\"orca-mini\",\n",
    "       temperature=0.0,\n",
    "       host=\"http://localhost:11434\"  # Default Ollama host\n",
    "   )\n",
    "   \n",
    "   # Setup the client\n",
    "   ollama_llm.setup_client()\n",
    "   \n",
    "   # Verify setup\n",
    "   print(f\"Ollama setup complete: {ollama_llm}\")\n",
    "except Exception as e:\n",
    "   print(f\"Error initializing Ollama: {e}. Make sure Ollama is running locally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8d153-3508-40ea-a743-7be3da78ab22",
   "metadata": {},
   "source": [
    "### Overall Initialization of LLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc9bcb-f327-4913-a9e4-2a7750197e29",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Code Explanation:</strong>This function initializes multiple language model (LLM) clients for different providers. It takes three API keys as parameters and returns a dictionary of configured LLM objects.\n",
    "\n",
    "1. First, it creates an empty dictionary called `llms` to store all the model instances.\n",
    "\n",
    "2. For Claude, OpenAI, and Gemini:\n",
    "   - It creates an instance of each LLM's wrapper class\n",
    "   - Sets the provided API key and a temperature of 0.0 (making responses deterministic/less random)\n",
    "   - Calls `setup_client()` which likely establishes the API connection\n",
    "   - Adds each instance to the `llms` dictionary with an appropriate key\n",
    "\n",
    "3. For Ollama:\n",
    "   - Unlike the cloud-based LLMs, Ollama runs locally and doesn't require an API key\n",
    "   - It attempts to initialize the Ollama client with the \"llama3\" model\n",
    "   - This is wrapped in a try/except block because Ollama might not be running locally\n",
    "   - If initialization fails, it prints a warning message but continues execution\n",
    "\n",
    "4. Finally, it returns the `llms` dictionary containing all successfully initialized LLM clients\n",
    "\n",
    "This pattern allows the code to work with multiple LLMs through a consistent interface, making it easy to swap between different providers or run comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f27bab7-fddf-46c6-94e2-eefcfeb4062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llms(claude_api_key, openai_api_key, gemini_api_key):\n",
    "    llms = {}\n",
    "    \n",
    "    # Initialize Claude\n",
    "    claude = ClaudeLLM(\n",
    "        api_key=claude_api_key,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    claude.setup_client()\n",
    "    llms[\"claude\"] = claude\n",
    "    \n",
    "    # Initialize OpenAI\n",
    "    openai_llm = OpenAILLM(\n",
    "        api_key=openai_api_key,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    openai_llm.setup_client()\n",
    "    llms[\"openai\"] = openai_llm\n",
    "    \n",
    "    # Initialize Gemini\n",
    "    gemini = GeminiLLM(\n",
    "        api_key=gemini_api_key,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    gemini.setup_client()\n",
    "    llms[\"gemini\"] = gemini\n",
    "    \n",
    "    # Initialize Ollama (no API key needed)\n",
    "    try:\n",
    "        ollama_llm = OllamaLLM(\n",
    "            model=\"llama3\",\n",
    "            temperature=0.0\n",
    "        )\n",
    "        ollama_llm.setup_client()\n",
    "        llms[\"ollama\"] = ollama_llm\n",
    "    except:\n",
    "        print(\"Warning: Could not initialize Ollama. Make sure it's running locally.\")\n",
    "    \n",
    "    return llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff4759-20bb-41c0-b841-cae3b7cb7b10",
   "metadata": {},
   "source": [
    "### Part 1 of MSA: Sentiment Bearings\n",
    "\n",
    "Here my plan involves developing sentiment analysis capabilities for Sepedi, Sotho, and Setswana languages by creating comprehensive sentiment bearing lexicons. These lexicons will catalog words with their corresponding sentiment values (positive +1, neutral 0, or negative -1) in a consistent format of \"<word> / <sentiment> / <rating>\". After establishing these language-specific sentiment dictionaries, I'll feed them to large language models and explore various prompting techniques to evaluate consistency in sentiment interpretation. This approach combines traditional lexicon-based methods with modern LLM capabilities, potentially addressing the resource gap for sentiment analysis in these South African languages. By systematically testing different prompting strategies, I aim to identify the most reliable method for accurate sentiment analysis across these three languages, providing a foundation for more nuanced text analysis applications in these underrepresented languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ba081-be78-4738-824a-fd402b85daf2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Code Explanation:</strong>\n",
    "\n",
    "This `MultilingualSentimentBearings` class provides a comprehensive framework for analyzing sentiment in three South African languages: Sepedi, Sesotho, and Setswana. Here's a breakdown of how it works:\n",
    "\n",
    "1. **Class Structure and Initialization**:\n",
    "   - The class defines a dictionary `LANGUAGES` mapping language codes to their full names\n",
    "   - The constructor takes an LLM model as input, which will be used for sentiment analysis\n",
    "   \n",
    "2. **Prompt Generation**:\n",
    "   - `get_bearing_prompt()` creates different styles of prompts for the LLM:\n",
    "     - \"default\": Basic prompt with simple examples\n",
    "     - \"zero_shot\": No examples, just instructions\n",
    "     - \"few_shot\": Includes language-specific examples\n",
    "     - \"in_context\": Adds cultural and project context\n",
    "   - Each prompt style follows the same output format: `<word>, <sentiment>, <score>`\n",
    "   - The prompts ensure consistency in responses while testing different prompting strategies\n",
    "\n",
    "3. **System Prompt Generation**:\n",
    "   - `get_bearing_system_prompt()` creates a system prompt that establishes the LLM's role as a sentiment analyzer for the specified language\n",
    "   - Emphasizes precision, cultural context, and format adherence\n",
    "\n",
    "4. **Word Analysis**:\n",
    "   - `analyze_word()` is the core method that:\n",
    "     - Validates the language\n",
    "     - Gets appropriate prompts\n",
    "     - Calls the LLM\n",
    "     - Parses the response into structured data\n",
    "     - Includes error handling for malformed responses\n",
    "   \n",
    "5. **Batch Processing**:\n",
    "   - `analyze_words()` processes multiple words across multiple languages\n",
    "   - Results are organized by language for easy analysis\n",
    "   \n",
    "6. **Lexicon Creation**:\n",
    "   - `create_sentiment_lexicon()` transforms analysis results into a usable sentiment lexicon\n",
    "   - The final output is a nested dictionary mapping languages to words to sentiment scores\n",
    "\n",
    "This class enables systematic comparison of different prompting techniques while building sentiment lexicons for languages with limited NLP resources. The robust error handling and structured output make it suitable for both research and practical applications in multilingual sentiment analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a822806c-1b27-43b1-8172-a5ba10105b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualSentimentBearings:\n",
    "      # Language codes and names\n",
    "    LANGUAGES = {\n",
    "        'sepedi': 'Sepedi',\n",
    "        'sesotho': 'Sesotho',\n",
    "        'setswana': 'Setswana'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, llm_model):\n",
    "        self.llm = llm_model\n",
    "        \n",
    "    def get_bearing_prompt(self, word, language, prompt_style=\"default\"):\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        if prompt_style == \"zero_shot\":\n",
    "            return f\"\"\"\n",
    "            Analyze the sentiment bearing of the {language_name} word: \"{word}\"\n",
    "            \n",
    "            Please respond with ONLY a single line in exactly this format:\n",
    "            <word>, <sentiment>, <score>\n",
    "            \n",
    "            Where:\n",
    "            - <word> is the analyzed word in {language_name}\n",
    "            - <sentiment> is either \"positive\", \"neutral\", or \"negative\" in English\n",
    "            - <score> is either 1 (positive), 0 (neutral), or -1 (negative)\n",
    "            \"\"\"\n",
    "            \n",
    "        elif prompt_style == \"few_shot\":\n",
    "            return f\"\"\"\n",
    "            Analyze the sentiment bearing of the {language_name} word: \"{word}\"\n",
    "            \n",
    "            Here are some examples of sentiment analysis in {language_name}:\n",
    "            \n",
    "            For Sepedi:\n",
    "            lerato (love), positive, 1\n",
    "            pefelo (anger), negative, -1\n",
    "            nako (time), neutral, 0\n",
    "            \n",
    "            For Sesotho:\n",
    "            thabo (joy), positive, 1\n",
    "            kgalefo (anger), negative, -1\n",
    "            ntlo (house), neutral, 0\n",
    "            \n",
    "            For Setswana:\n",
    "            boitumelo (happiness), positive, 1\n",
    "            kutlobotlhoko (sadness), negative, -1\n",
    "            setulo (chair), neutral, 0\n",
    "            \n",
    "            Please respond with ONLY a single line in exactly this format:\n",
    "            <word>, <sentiment>, <score>\n",
    "            \n",
    "            Where:\n",
    "            - <word> is the analyzed word in {language_name}\n",
    "            - <sentiment> is either \"positive\", \"neutral\", or \"negative\" in English\n",
    "            - <score> is either 1 (positive), 0 (neutral), or -1 (negative)\n",
    "            \"\"\"\n",
    "            \n",
    "        elif prompt_style == \"in_context\":\n",
    "            return f\"\"\"\n",
    "            You are analyzing text sentiment in African languages. \n",
    "            \n",
    "            TASK CONTEXT:\n",
    "            - You are helping to build sentiment lexicons for {language_name}, which lacks NLP resources\n",
    "            - These lexicons will power sentiment analysis tools for local languages\n",
    "            - Cultural context is critical to accurate sentiment determination\n",
    "            \n",
    "            Now analyze the sentiment bearing of the {language_name} word: \"{word}\"\n",
    "            \n",
    "            Please respond with ONLY a single line in exactly this format:\n",
    "            <word>, <sentiment>, <score>\n",
    "            \n",
    "            Where:\n",
    "            - <word> is the analyzed word in {language_name}\n",
    "            - <sentiment> is either \"positive\", \"neutral\", or \"negative\" in English\n",
    "            - <score> is either 1 (positive), 0 (neutral), or -1 (negative)\n",
    "            \"\"\"\n",
    "            \n",
    "        else:  # default\n",
    "            return f\"\"\"\n",
    "            Analyze the sentiment bearing of the {language_name} word: \"{word}\"\n",
    "            \n",
    "            Please respond with ONLY a single line in exactly this format:\n",
    "            <word>, <sentiment>, <score>\n",
    "            \n",
    "            Where:\n",
    "            - <word> is the analyzed word in {language_name}\n",
    "            - <sentiment> is either \"positive\", \"neutral\", or \"negative\" in English\n",
    "            - <score> is either 1 (positive), 0 (neutral), or -1 (negative)\n",
    "            \n",
    "            For example:\n",
    "            lerato, positive, 1\n",
    "            thata, neutral, 0\n",
    "            bohloko, negative, -1\n",
    "            \"\"\"\n",
    "    \n",
    "    def get_bearing_system_prompt(self, language):\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        return f\"\"\"\n",
    "        You are a precise sentiment analyzer for the {language_name} language. Your task is to determine \n",
    "        if a {language_name} word has a positive, neutral, or negative sentiment bearing.\n",
    "        \n",
    "        Respond with ONLY a single line containing the word, sentiment (in English), and score (-1, 0, or 1) \n",
    "        in the exact format requested. Do not include any explanations or additional text.\n",
    "        \n",
    "        Be objective in your analysis and ensure you understand the cultural context and nuances of \n",
    "        the {language_name} language.\n",
    "        \"\"\"\n",
    "    \n",
    "    def analyze_word(self, word, language, prompt_style=\"default\"):\n",
    "        if language.lower() not in self.LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language: {language}. Supported languages are: {', '.join(self.LANGUAGES.keys())}\")\n",
    "        \n",
    "        prompt = self.get_bearing_prompt(word, language, prompt_style)\n",
    "        system_prompt = self.get_bearing_system_prompt(language)\n",
    "        \n",
    "        # Get response from the LLM\n",
    "        response = self.llm.generate(prompt, system_prompt=system_prompt)\n",
    "        \n",
    "        # Parse the response (expecting format: \"word, sentiment, score\")\n",
    "        try:\n",
    "            # Clean the response and split by comma\n",
    "            clean_response = response.strip()\n",
    "            parts = clean_response.split(',')\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                analyzed_word = parts[0].strip()\n",
    "                sentiment = parts[1].strip().lower()\n",
    "                score_str = parts[2].strip()\n",
    "                \n",
    "                # Convert score to int\n",
    "                try:\n",
    "                    score = int(score_str)\n",
    "                except ValueError:\n",
    "                    # If score is not an integer, try to extract it from the string\n",
    "                    if '-1' in score_str:\n",
    "                        score = -1\n",
    "                    elif '1' in score_str and not score_str.startswith('-'):\n",
    "                        score = 1\n",
    "                    else:\n",
    "                        score = 0\n",
    "                \n",
    "                return {\n",
    "                    'word': analyzed_word,\n",
    "                    'language': language.lower(),\n",
    "                    'sentiment': sentiment,\n",
    "                    'score': score,\n",
    "                    'prompt_style': prompt_style\n",
    "                }\n",
    "            else:\n",
    "                # If parsing fails, return a default response\n",
    "                print(f\"Warning: Could not parse LLM response correctly. Raw response: {response}\")\n",
    "                return {\n",
    "                    'word': word,\n",
    "                    'language': language.lower(),\n",
    "                    'sentiment': 'unknown',\n",
    "                    'score': None,\n",
    "                    'prompt_style': prompt_style,\n",
    "                    'raw_response': response\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing LLM response: {e}\")\n",
    "            return {\n",
    "                'word': word,\n",
    "                'language': language.lower(),\n",
    "                'sentiment': 'error',\n",
    "                'score': None,\n",
    "                'prompt_style': prompt_style,\n",
    "                'error': str(e),\n",
    "                'raw_response': response\n",
    "            }\n",
    "    \n",
    "    def analyze_words(self, words_dict, prompt_style=\"default\"):\n",
    "        results = {}\n",
    "        \n",
    "        for language, words in words_dict.items():\n",
    "            language_results = []\n",
    "            \n",
    "            for word in words:\n",
    "                result = self.analyze_word(word, language, prompt_style)\n",
    "                language_results.append(result)\n",
    "                \n",
    "            results[language] = language_results\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def create_sentiment_lexicon(self, words_dict, prompt_style=\"default\"):\n",
    "        lexicon = {}\n",
    "        \n",
    "        for language, words in words_dict.items():\n",
    "            language_lexicon = {}\n",
    "            \n",
    "            for word in words:\n",
    "                result = self.analyze_word(word, language, prompt_style)\n",
    "                if result['score'] is not None:\n",
    "                    language_lexicon[word] = result['score']\n",
    "                \n",
    "            lexicon[language] = language_lexicon\n",
    "            \n",
    "        return lexicon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc35a2-6fe3-4b70-ab16-5e69c2b4a2ce",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Code Explanation:</strong>\n",
    "\n",
    "This code sets up the test infrastructure for a multilingual sentiment analysis experiment across three South African languages (Sepedi, Sesotho, and Setswana). Here's what each component does:\n",
    "\n",
    "1. **Test Data Definition**:\n",
    "   - Creates a dictionary `test_words` containing sample words for each language\n",
    "   - The words are strategically selected to include emotional concepts (joy, sadness), relationship concepts (love), and more neutral concepts (interest)\n",
    "   - Some words (like \"thabo\" for joy) appear in multiple languages, enabling cross-language consistency testing\n",
    "\n",
    "2. **Prompt Style Configuration**:\n",
    "   - Defines four different prompting strategies to test with each LLM:\n",
    "     - \"default\": Basic instruction with simple examples\n",
    "     - \"zero_shot\": Instructions without examples\n",
    "     - \"few_shot\": Instructions with language-specific examples\n",
    "     - \"in_context\": Instructions with added cultural and project context\n",
    "   - This enables systematic comparison of prompting techniques for sentiment analysis\n",
    "\n",
    "3. **Results Display Function**:\n",
    "   - `display_language_results()` formats and prints analysis results in a readable table\n",
    "   - Uses string formatting to align columns for better readability\n",
    "   - Extracts word, sentiment, score, and prompt style from each result object\n",
    "   - Handles missing or unknown values gracefully with default values\n",
    "\n",
    "4. **LLM Testing Function**:\n",
    "   - `test_llm_sentiment()` provides a reusable way to test any LLM\n",
    "   - Creates a sentiment analyzer using the provided LLM\n",
    "   - Tests all four prompting styles sequentially\n",
    "   - Processes results for all languages and words\n",
    "   - Creates a sentiment lexicon using the \"in_context\" prompting style\n",
    "   - Includes comprehensive error handling to continue testing even if one LLM fails\n",
    "   - Returns the analyzer instance for later use in cross-LLM comparisons\n",
    "\n",
    "This modular design eliminates code duplication while maintaining the ability to test each LLM independently. The standardized format makes results comparable across different models and prompting techniques, supporting rigorous analysis of sentiment detection capabilities in these under-resourced languages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f598e0aa-f033-494f-986a-42b9e87a2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Define test words and utilities\n",
    "\n",
    "# Sample words in each language\n",
    "test_words = {\n",
    "    'sepedi': [\n",
    "        'manyami',     # sadness\n",
    "        'thabo',       # joy\n",
    "        'kgahlego',    # interest\n",
    "    ],\n",
    "    'sesotho': [\n",
    "        'lerato',      # love\n",
    "        'thabo',       # joy\n",
    "        'thahasello',  # interest\n",
    "    ],\n",
    "    'setswana': [\n",
    "        'botlhoko',    # pain\n",
    "        'boitumelo',   # happiness\n",
    "        'kgatlhego',   # interest\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Prompt styles to test\n",
    "prompt_styles = [\"default\", \"zero_shot\", \"few_shot\", \"in_context\"]\n",
    "\n",
    "# Function to display sentiment analysis results\n",
    "def display_language_results(language, results):\n",
    "    print(f\"\\nSentiment Analysis Results for {language.title()}:\")\n",
    "    print(f\"{'Word':<15} | {'Sentiment':<10} | {'Score':<5} | {'Prompt Style':<12}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for result in results:\n",
    "        word = result.get('word', 'unknown')\n",
    "        sentiment = result.get('sentiment', 'unknown')\n",
    "        score = result.get('score', 'N/A')\n",
    "        prompt_style = result.get('prompt_style', 'default')\n",
    "        \n",
    "        print(f\"{word:<15} | {sentiment:<10} | {score:<5} | {prompt_style:<12}\")\n",
    "\n",
    "# Function to run tests for a single LLM\n",
    "def test_llm_sentiment(llm, llm_name):\n",
    "    try:\n",
    "        # Create a MultilingualSentimentBearings instance\n",
    "        analyzer = MultilingualSentimentBearings(llm)\n",
    "        print(f\"{llm_name} sentiment analyzer initialized successfully\")\n",
    "        \n",
    "        # Test each prompt style\n",
    "        for style in prompt_styles:\n",
    "            print(f\"\\n=== Testing {llm_name} with {style.upper()} prompting style ===\")\n",
    "            \n",
    "            # Analyze words\n",
    "            results = analyzer.analyze_words(test_words, prompt_style=style)\n",
    "            \n",
    "            # Display results for each language\n",
    "            for language, language_results in results.items():\n",
    "                display_language_results(language, language_results)\n",
    "        \n",
    "        # Create a sentiment lexicon\n",
    "        print(f\"\\n=== Creating {llm_name} Sentiment Lexicon ===\")\n",
    "        lexicon = analyzer.create_sentiment_lexicon(test_words, prompt_style=\"in_context\")\n",
    "        \n",
    "        # Display the lexicon\n",
    "        print(f\"\\n{llm_name} Sentiment Lexicon:\")\n",
    "        for language, words in lexicon.items():\n",
    "            print(f\"\\n{language.title()}:\")\n",
    "            for word, score in words.items():\n",
    "                sentiment = \"positive\" if score > 0 else \"negative\" if score < 0 else \"neutral\"\n",
    "                print(f\"  {word:<15}: {sentiment:<10} ({score})\")\n",
    "        \n",
    "        print(f\"\\n{llm_name} sentiment analysis testing completed successfully\")\n",
    "        return analyzer\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {llm_name} sentiment testing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791c0be-d791-4a33-a29f-31b123221578",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1ecff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Claude Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd61d36-225e-416a-8fde-941309ca17e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude sentiment analyzer initialized successfully\n",
      "\n",
      "=== Testing Claude with DEFAULT prompting style ===\n",
      "\n",
      "Sentiment Analysis Results for Sepedi:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "manyami         | negative   | -1    | default     \n",
      "thabo           | positive   | 1     | default     \n",
      "kgahlego        | positive   | 1     | default     \n",
      "\n",
      "Sentiment Analysis Results for Sesotho:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "lerato          | positive   | 1     | default     \n",
      "thabo           | positive   | 1     | default     \n",
      "thahasello      | positive   | 1     | default     \n",
      "\n",
      "Sentiment Analysis Results for Setswana:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "botlhoko        | negative   | -1    | default     \n",
      "boitumelo       | positive   | 1     | default     \n",
      "kgatlhego       | positive   | 1     | default     \n",
      "\n",
      "=== Testing Claude with ZERO_SHOT prompting style ===\n",
      "\n",
      "Sentiment Analysis Results for Sepedi:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "manyami         | negative   | -1    | zero_shot   \n",
      "thabo           | positive   | 1     | zero_shot   \n",
      "kgahlego        | positive   | 1     | zero_shot   \n",
      "\n",
      "Sentiment Analysis Results for Sesotho:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "lerato          | positive   | 1     | zero_shot   \n",
      "thabo           | positive   | 1     | zero_shot   \n",
      "thahasello      | positive   | 1     | zero_shot   \n",
      "\n",
      "Sentiment Analysis Results for Setswana:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "botlhoko        | negative   | -1    | zero_shot   \n",
      "boitumelo       | positive   | 1     | zero_shot   \n",
      "kgatlhego       | positive   | 1     | zero_shot   \n",
      "\n",
      "=== Testing Claude with FEW_SHOT prompting style ===\n",
      "\n",
      "Sentiment Analysis Results for Sepedi:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "manyami         | negative   | -1    | few_shot    \n",
      "thabo           | positive   | 1     | few_shot    \n",
      "kgahlego        | positive   | 1     | few_shot    \n",
      "\n",
      "Sentiment Analysis Results for Sesotho:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "lerato          | positive   | 1     | few_shot    \n",
      "thabo           | positive   | 1     | few_shot    \n",
      "thahasello      | positive   | 1     | few_shot    \n",
      "\n",
      "Sentiment Analysis Results for Setswana:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "botlhoko        | negative   | -1    | few_shot    \n",
      "boitumelo       | positive   | 1     | few_shot    \n",
      "kgatlhego       | positive   | 1     | few_shot    \n",
      "\n",
      "=== Testing Claude with IN_CONTEXT prompting style ===\n",
      "\n",
      "Sentiment Analysis Results for Sepedi:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "manyami         | negative   | -1    | in_context  \n",
      "thabo           | positive   | 1     | in_context  \n",
      "kgahlego        | positive   | 1     | in_context  \n",
      "\n",
      "Sentiment Analysis Results for Sesotho:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "lerato          | positive   | 1     | in_context  \n",
      "thabo           | positive   | 1     | in_context  \n",
      "thahasello      | positive   | 1     | in_context  \n",
      "\n",
      "Sentiment Analysis Results for Setswana:\n",
      "Word            | Sentiment  | Score | Prompt Style\n",
      "-------------------------------------------------------\n",
      "botlhoko        | negative   | -1    | in_context  \n",
      "boitumelo       | positive   | 1     | in_context  \n",
      "kgatlhego       | positive   | 1     | in_context  \n",
      "\n",
      "=== Creating Claude Sentiment Lexicon ===\n",
      "\n",
      "Claude Sentiment Lexicon:\n",
      "\n",
      "Sepedi:\n",
      "  manyami        : negative   (-1)\n",
      "  thabo          : positive   (1)\n",
      "  kgahlego       : positive   (1)\n",
      "\n",
      "Sesotho:\n",
      "  lerato         : positive   (1)\n",
      "  thabo          : positive   (1)\n",
      "  thahasello     : positive   (1)\n",
      "\n",
      "Setswana:\n",
      "  botlhoko       : negative   (-1)\n",
      "  boitumelo      : positive   (1)\n",
      "  kgatlhego      : positive   (1)\n",
      "\n",
      "Claude sentiment analysis testing completed successfully\n"
     ]
    }
   ],
   "source": [
    "claude_analyzer = test_llm_sentiment(claude, \"Claude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262cf91-b9ce-418e-b83d-080589144a95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #b5e64c; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Open AI Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a557ca-c12d-44ed-ad8f-182143615732",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_analyzer = test_llm_sentiment(openai_llm, \"OpenAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc7d65-de77-444b-bfb6-5ce7fe802905",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e393ed; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Gemini Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99149484-cc4a-4756-abbc-64c7cff4f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini sentiment analyzer initialized successfully\n",
      "\n",
      "=== Testing Gemini with DEFAULT prompting style ===\n",
      "Error in Gemini sentiment testing: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Gemini Test\n",
    "gemini_analyzer = test_llm_sentiment(gemini_llm, \"Gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e5ea5-fd13-491d-a2c6-dd3c20a01bea",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f593a5; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Ollama Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e97782c-d47c-42f1-9ccb-78aea8ed7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama sentiment analyzer initialized successfully\n",
      "\n",
      "=== Testing Ollama with DEFAULT prompting style ===\n",
      "Error in Ollama sentiment testing: model requires more system memory (5.1 GiB) than is available (5.1 GiB) (status code: 500)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Ollama Test\n",
    "ollama_analyzer = test_llm_sentiment(ollama_llm, \"Ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dbea0f-00f3-47cc-8ce3-443deffb9855",
   "metadata": {},
   "source": [
    "### Part 2 of MSA: Sentiment Classifications\n",
    "\n",
    "In this phase, we're elevating our sentiment analysis from individual words to complete sentences across Sepedi, Sesotho, and Setswana languages. We're testing how different LLMs (Claude, OpenAI, Gemini, and Ollama) classify the emotional tone of authentic sentences as positive, negative, or neutral. By comparing classification consistency across models and prompt styles, we aim to identify the most reliable approach for sentiment analysis in these under-resourced languages. This builds on our word-level sentiment bearings to develop more nuanced text understanding capabilities that respect cultural and linguistic context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb6d1d-be2f-47a7-813e-c289d969abdc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1f3d1; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Code Explanation:</strong>\n",
    "\n",
    "This code implements a multilingual sentiment classification framework for analyzing text sentiment in three South African languages: Sepedi, Sesotho, and Setswana. Here's a breakdown of how it works:\n",
    "\n",
    "1. **Test Data Setup**:\n",
    "   - Defines a dictionary of test sentences in each language with their English translations\n",
    "   - Each language includes positive, negative, and neutral examples to test classification accuracy\n",
    "   - Also defines prompt styles to test different LLM prompting approaches\n",
    "\n",
    "2. **MultilingualSentimentClassifier Class**:\n",
    "   - Core class for sentence-level sentiment analysis across languages\n",
    "   - Maintains language mappings and handles the LLM interaction\n",
    "\n",
    "3. **Prompt Generation**:\n",
    "   - Implements four different prompting strategies:\n",
    "     - \"default\": Basic classification with contextual hints\n",
    "     - \"zero_shot\": Simple instructions without examples\n",
    "     - \"few_shot\": Includes language-specific examples to guide the model\n",
    "     - \"in_context\": Adds cultural and project context for better performance\n",
    "\n",
    "4. **Classification Logic**:\n",
    "   - `classify_text()` handles individual text classification:\n",
    "     - Validates language support\n",
    "     - Constructs appropriate prompts\n",
    "     - Calls the LLM\n",
    "     - Parses the response to extract sentiment\n",
    "     - Includes fallback parsing for unexpected response formats\n",
    "   - `classify_texts()` processes multiple texts across languages\n",
    "\n",
    "5. **Output and Display**:\n",
    "   - `display_classification_results()` formats and displays results in a readable table\n",
    "   - Truncates long texts for better display formatting\n",
    "\n",
    "6. **Test Framework**:\n",
    "   - `test_llm_classification()` provides a standardized way to:\n",
    "     - Initialize a classifier with a specific LLM\n",
    "     - Test all prompt styles\n",
    "     - Process results across all languages\n",
    "     - Handle errors gracefully\n",
    "\n",
    "This code enables systematic evaluation of different LLMs' ability to perform sentiment analysis on complete sentences in low-resource languages, comparing various prompt engineering approaches to identify optimal strategies for multilingual sentiment classification.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47dce4d1-9290-4807-a2a0-aad53b1693c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Define test sentences and utilities\n",
    "\n",
    "# Sample sentences in each language\n",
    "test_sentences = {\n",
    "    'sepedi': [\n",
    "        \"Ke thabile go bona gore o atlega mo dithutong tša gago.\", # I'm happy to see that you're succeeding in your studies.\n",
    "        \"Ga ke rate maitshwaro a gago.\", # I don't like your behavior.\n",
    "        \"Pula e a na lehono.\", # It's raining today.\n",
    "    ],\n",
    "    'sesotho': [\n",
    "        \"Ke thabile ho bona batho ba bangata ba tshehetsana.\", # I'm happy to see many people supporting each other.\n",
    "        \"Ha ke batle ho bua le motho ya ntseng a bua hampe ka batho.\", # I don't want to talk to someone who speaks badly about people.\n",
    "        \"Buka ena e fuwe ke titjhere.\", # This book was given by the teacher.\n",
    "    ],\n",
    "    'setswana': [\n",
    "        \"Ke itumetse thata go bona ditsala tsa me.\", # I'm very happy to see my friends.\n",
    "        \"Ga ke rate go dira le batho ba ba sa tseyeng tiro ya bone ka tlhoafalo.\", # I don't like working with people who don't take their work seriously.\n",
    "        \"Setlhare se se kwa pele ga ntlo.\", # The tree is in front of the house.\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Prompt styles to test\n",
    "prompt_styles = [\"default\", \"zero_shot\", \"few_shot\", \"in_context\"]\n",
    "\n",
    "class MultilingualSentimentClassifier:\n",
    "    # Language codes and names\n",
    "    LANGUAGES = {\n",
    "        'sepedi': 'Sepedi',\n",
    "        'sesotho': 'Sesotho',\n",
    "        'setswana': 'Setswana'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, llm_model):\n",
    "        self.llm = llm_model\n",
    "        \n",
    "    def get_classification_prompt(self, text, language, prompt_style=\"default\"):\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        if prompt_style == \"zero_shot\":\n",
    "            return f\"\"\"\n",
    "            Classify the overall sentiment of the following {language_name} text as 'positive', 'negative', or 'neutral'.\n",
    "            Text: \"{text}\"\n",
    "            \n",
    "            Provide the result in exactly this format:\n",
    "            Sentiment: <positive/negative/neutral>\n",
    "            \"\"\"\n",
    "            \n",
    "        elif prompt_style == \"few_shot\":\n",
    "            return f\"\"\"\n",
    "            Classify the overall sentiment of the following {language_name} text.\n",
    "            \n",
    "            Here are some examples:\n",
    "            \n",
    "            Sepedi example 1: \"Ke rata go raloka le bana ba ka.\" (I like playing with my children.)\n",
    "            Sentiment: positive\n",
    "            \n",
    "            Sepedi example 2: \"Ga ke na tshelete ya go reka dijo.\" (I don't have money to buy food.)\n",
    "            Sentiment: negative\n",
    "            \n",
    "            Sepedi example 3: \"Re tla kopana ka Mosupologo.\" (We will meet on Monday.)\n",
    "            Sentiment: neutral\n",
    "            \n",
    "            Now classify this {language_name} text: \"{text}\"\n",
    "            \n",
    "            Provide the result in exactly this format:\n",
    "            Sentiment: <positive/negative/neutral>\n",
    "            \"\"\"\n",
    "            \n",
    "        elif prompt_style == \"in_context\":\n",
    "            return f\"\"\"\n",
    "            You are analyzing text sentiment in African languages. \n",
    "            \n",
    "            TASK CONTEXT:\n",
    "            - You are helping to build sentiment analysis tools for {language_name}, which lacks NLP resources\n",
    "            - Cultural context is critical to accurate sentiment determination\n",
    "            - Even subtle emotional cues in the language should be considered\n",
    "            \n",
    "            Analyze the sentiment of this {language_name} text: \"{text}\"\n",
    "            \n",
    "            Provide the result in exactly this format:\n",
    "            Sentiment: <positive/negative/neutral>\n",
    "            \"\"\"\n",
    "            \n",
    "        else:  # default\n",
    "            return f\"\"\"\n",
    "            Classify the overall sentiment of the following {language_name} text as 'positive', 'negative', or 'neutral'.\n",
    "            Text: \"{text}\"\n",
    "            \n",
    "            Consider the emotional tone, cultural context, and any sentiment-bearing words.\n",
    "            \n",
    "            Provide the result in exactly this format:\n",
    "            Sentiment: <positive/negative/neutral>\n",
    "            \"\"\"\n",
    "    \n",
    "    def get_classification_system_prompt(self, language):\n",
    "        language_name = self.LANGUAGES.get(language.lower(), language)\n",
    "        \n",
    "        return f\"\"\"\n",
    "        You are a precise sentiment classifier for the {language_name} language. Your task is to determine \n",
    "        if a {language_name} text has a positive, negative, or neutral sentiment.\n",
    "        \n",
    "        Respond with ONLY the sentiment classification in the exact format requested. \n",
    "        Do not include any explanations or additional text.\n",
    "        \n",
    "        Be objective in your analysis and ensure you understand the cultural context and nuances of \n",
    "        the {language_name} language.\n",
    "        \"\"\"\n",
    "    \n",
    "    def classify_text(self, text, language, prompt_style=\"default\"):\n",
    "        if language.lower() not in self.LANGUAGES:\n",
    "            raise ValueError(f\"Unsupported language: {language}. Supported languages are: {', '.join(self.LANGUAGES.keys())}\")\n",
    "        \n",
    "        prompt = self.get_classification_prompt(text, language, prompt_style)\n",
    "        system_prompt = self.get_classification_system_prompt(language)\n",
    "        \n",
    "        # Get response from the LLM\n",
    "        response = self.llm.generate(prompt, system_prompt=system_prompt)\n",
    "        \n",
    "        # Parse the response (expecting format: \"Sentiment: positive/negative/neutral\")\n",
    "        try:\n",
    "            # Clean the response\n",
    "            clean_response = response.strip().lower()\n",
    "            \n",
    "            # Extract sentiment\n",
    "            if \"sentiment:\" in clean_response:\n",
    "                sentiment_part = clean_response.split(\"sentiment:\")[1].strip()\n",
    "                if \"positive\" in sentiment_part:\n",
    "                    sentiment = \"positive\"\n",
    "                elif \"negative\" in sentiment_part:\n",
    "                    sentiment = \"negative\"\n",
    "                else:\n",
    "                    sentiment = \"neutral\"\n",
    "            else:\n",
    "                # Fallback parsing if format is not as expected\n",
    "                if \"positive\" in clean_response:\n",
    "                    sentiment = \"positive\"\n",
    "                elif \"negative\" in clean_response:\n",
    "                    sentiment = \"negative\"\n",
    "                else:\n",
    "                    sentiment = \"neutral\"\n",
    "            \n",
    "            return {\n",
    "                'text': text,\n",
    "                'language': language.lower(),\n",
    "                'sentiment': sentiment,\n",
    "                'prompt_style': prompt_style\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing LLM response: {e}\")\n",
    "            return {\n",
    "                'text': text,\n",
    "                'language': language.lower(),\n",
    "                'sentiment': 'error',\n",
    "                'prompt_style': prompt_style,\n",
    "                'error': str(e),\n",
    "                'raw_response': response\n",
    "            }\n",
    "    \n",
    "    def classify_texts(self, texts_dict, prompt_style=\"default\"):\n",
    "        results = {}\n",
    "        \n",
    "        for language, texts in texts_dict.items():\n",
    "            language_results = []\n",
    "            \n",
    "            for text in texts:\n",
    "                result = self.classify_text(text, language, prompt_style)\n",
    "                language_results.append(result)\n",
    "                \n",
    "            results[language] = language_results\n",
    "            \n",
    "        return results\n",
    "\n",
    "# Function to display sentiment classification results\n",
    "def display_classification_results(language, results):\n",
    "    print(f\"\\nSentiment Classification Results for {language.title()}:\")\n",
    "    print(f\"{'Text':<50} | {'Sentiment':<10} | {'Prompt Style':<12}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for result in results:\n",
    "        text = result.get('text', 'unknown')\n",
    "        # Truncate long texts for better display\n",
    "        if len(text) > 45:\n",
    "            text = text[:42] + \"...\"\n",
    "        sentiment = result.get('sentiment', 'unknown')\n",
    "        prompt_style = result.get('prompt_style', 'default')\n",
    "        \n",
    "        print(f\"{text:<50} | {sentiment:<10} | {prompt_style:<12}\")\n",
    "\n",
    "# Function to run tests for a single LLM\n",
    "def test_llm_classification(llm, llm_name):\n",
    "    try:\n",
    "        # Create a MultilingualSentimentClassifier instance\n",
    "        classifier = MultilingualSentimentClassifier(llm)\n",
    "        print(f\"{llm_name} sentiment classifier initialized successfully\")\n",
    "        \n",
    "        # Test each prompt style\n",
    "        for style in prompt_styles:\n",
    "            print(f\"\\n=== Testing {llm_name} with {style.upper()} prompting style ===\")\n",
    "            \n",
    "            # Classify texts\n",
    "            results = classifier.classify_texts(test_sentences, prompt_style=style)\n",
    "            \n",
    "            # Display results for each language\n",
    "            for language, language_results in results.items():\n",
    "                display_classification_results(language, language_results)\n",
    "        \n",
    "        print(f\"\\n{llm_name} sentiment classification testing completed successfully\")\n",
    "        return classifier\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {llm_name} sentiment classification testing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b08ec-df04-4a10-961b-58a4d1bfe274",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #d1ecff; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Claude Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af1c29-f1fd-49d3-b03b-9dbd7022233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude sentiment classifier initialized successfully\n",
      "\n",
      "=== Testing Claude with DEFAULT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | default     \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | default     \n",
      "Pula e a na lehono.                                | neutral    | default     \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | default     \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | default     \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | default     \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | default     \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | default     \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | default     \n",
      "\n",
      "=== Testing Claude with ZERO_SHOT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | zero_shot   \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | zero_shot   \n",
      "Pula e a na lehono.                                | neutral    | zero_shot   \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | zero_shot   \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | zero_shot   \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | zero_shot   \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | zero_shot   \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | zero_shot   \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | zero_shot   \n",
      "\n",
      "=== Testing Claude with FEW_SHOT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | few_shot    \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | few_shot    \n",
      "Pula e a na lehono.                                | neutral    | few_shot    \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | few_shot    \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | few_shot    \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | few_shot    \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | few_shot    \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | few_shot    \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | few_shot    \n",
      "\n",
      "=== Testing Claude with IN_CONTEXT prompting style ===\n"
     ]
    }
   ],
   "source": [
    "claude_classifier = test_llm_classification(claude, \"Claude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc783fa-9f22-407c-80ec-bc9bcf2142db",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #b5e64c; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Open AI Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b0867a4-2f17-4787-a1c7-d1d892b29c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI sentiment classifier initialized successfully\n",
      "\n",
      "=== Testing OpenAI with DEFAULT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | default     \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | default     \n",
      "Pula e a na lehono.                                | neutral    | default     \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | default     \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | default     \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | default     \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | default     \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | default     \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | default     \n",
      "\n",
      "=== Testing OpenAI with ZERO_SHOT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | zero_shot   \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | zero_shot   \n",
      "Pula e a na lehono.                                | neutral    | zero_shot   \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | zero_shot   \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | zero_shot   \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | zero_shot   \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | zero_shot   \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | zero_shot   \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | zero_shot   \n",
      "\n",
      "=== Testing OpenAI with FEW_SHOT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | few_shot    \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | few_shot    \n",
      "Pula e a na lehono.                                | neutral    | few_shot    \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | few_shot    \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | few_shot    \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | few_shot    \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | few_shot    \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | few_shot    \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | few_shot    \n",
      "\n",
      "=== Testing OpenAI with IN_CONTEXT prompting style ===\n",
      "\n",
      "Sentiment Classification Results for Sepedi:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile go bona gore o atlega mo dithut...      | positive   | in_context  \n",
      "Ga ke rate maitshwaro a gago.                      | negative   | in_context  \n",
      "Pula e a na lehono.                                | neutral    | in_context  \n",
      "\n",
      "Sentiment Classification Results for Sesotho:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke thabile ho bona batho ba bangata ba tsh...      | positive   | in_context  \n",
      "Ha ke batle ho bua le motho ya ntseng a bu...      | negative   | in_context  \n",
      "Buka ena e fuwe ke titjhere.                       | neutral    | in_context  \n",
      "\n",
      "Sentiment Classification Results for Setswana:\n",
      "Text                                               | Sentiment  | Prompt Style\n",
      "---------------------------------------------------------------------------\n",
      "Ke itumetse thata go bona ditsala tsa me.          | positive   | in_context  \n",
      "Ga ke rate go dira le batho ba ba sa tseye...      | negative   | in_context  \n",
      "Setlhare se se kwa pele ga ntlo.                   | neutral    | in_context  \n",
      "\n",
      "OpenAI sentiment classification testing completed successfully\n"
     ]
    }
   ],
   "source": [
    "openai_classifier = test_llm_classification(openai_llm, \"OpenAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ea1f2-08d5-4748-96af-9790796a4e99",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e393ed; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Gemini Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a115d-d664-400b-9b1a-f33c472dd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_classifier = test_llm_classification(gemini, \"Gemini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02874e8-cc6f-48a1-92d7-3a180575d6af",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f593a5; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>Ollama Results</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f242ebb-a807-4c57-96a6-c506805c0290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama sentiment classifier initialized successfully\n",
      "\n",
      "=== Testing Ollama with DEFAULT prompting style ===\n"
     ]
    }
   ],
   "source": [
    "ollama_classifier = test_llm_classification(ollama_llm, \"Ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e59ed-51c5-4ed8-889f-00549e993cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
